# -*- coding: utf-8 -*-
"""FDA LO3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15jDuPYJ1an4ekvDapKZZn_WA2r3m0CEg
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.ensemble import IsolationForest

# Load dataset (assuming you already have 'credit_card_transactions_with_labels.csv' loaded)
df = pd.read_csv('credit_card_transactions.csv')

#Checking for null values
df.isnull().sum()

#Handling missing values - Numerical data
df['Card_Number'] = df['Card_Number'].fillna(df['Card_Number'].median())
df['Amount'] = df['Amount'].fillna(df['Amount'].median())

#Handling missing values - Categorical data
df['Merchant'] = df['Merchant'].fillna(df['Merchant'].mode()[0])
df['Transaction_Type'] = df['Transaction_Type'].fillna(df['Transaction_Type'].mode()[0])

#Re-checking for null values
df.isna().sum()

#Data Description
df.describe()

# Feature engineering: Convert categorical variables to numerical
df = pd.get_dummies(df, columns=['Merchant', 'Transaction_Type'])

df.head()

# Check dimensions of features before scaling
print("Shape of original dataframe:", df.shape)

# Split data into features (X) and target (y)
X = df.drop(['Transaction_Type_Fraudulent','Date'], axis=1)
y = df['Transaction_Type_Fraudulent']

# Scale numerical features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

X_scaled

# Anomaly detection using Isolation Forest
iso_forest = IsolationForest(contamination=0.01)
iso_forest.fit(X_scaled)
anomaly_preds = iso_forest.predict(X_scaled)
anomaly_preds = np.where(anomaly_preds == -1, 1, 0)  # Convert predictions to 1 (anomaly) and 0 (normal)

# Visualize anomalies detected by Isolation Forest
plt.figure(figsize=(10, 6))
plt.scatter(X.index, X['Amount'], c=anomaly_preds, cmap='viridis', marker='x', alpha=0.6)
plt.colorbar(label='Anomaly (1: Yes, 0: No)')
plt.title('Anomalies Detected by Isolation Forest')
plt.xlabel('Index')
plt.ylabel('Amount')
plt.show()

# Split data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=0)

# Model 1: Random Forest Classifier
rf_clf = RandomForestClassifier(random_state=0)
rf_clf.fit(X_train, y_train)
y_pred_rf = rf_clf.predict(X_test)

# Model 1 evaluation
accuracy_rf = accuracy_score(y_test, y_pred_rf)
print(f"Random Forest Classifier Accuracy: {accuracy_rf:.4f}")
print("Random Forest Classifier Report:")
print(classification_report(y_test, y_pred_rf))

# Confusion matrix for Random Forest Classifier
cm_rf = confusion_matrix(y_test, y_pred_rf)
plt.figure(figsize=(8, 6))
sns.heatmap(cm_rf, annot=True, cmap='Blues', fmt='d', cbar=False,
            annot_kws={'fontsize': 15}, linewidths=0.5, linecolor='black')
plt.title('Confusion Matrix - Random Forest Classifier')
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.show()

# Model 2: Decision Tree Classifier
dt_clf = DecisionTreeClassifier(random_state=0)
dt_clf.fit(X_train, y_train)
y_pred_dt = dt_clf.predict(X_test)

# Model 2 evaluation
accuracy_dt = accuracy_score(y_test, y_pred_dt)
print(f"\nDecision Tree Classifier Accuracy: {accuracy_dt:.4f}")
print("Decision Tree Classifier Report:")
print(classification_report(y_test, y_pred_dt))

# Confusion matrix for Decision Tree Classifier
cm_dt = confusion_matrix(y_test, y_pred_dt)
plt.figure(figsize=(8, 6))
sns.heatmap(cm_dt, annot=True, cmap='Greens', fmt='d', cbar=False,
            annot_kws={'fontsize': 15}, linewidths=0.5, linecolor='black')
plt.title('Confusion Matrix - Decision Tree Classifier')
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.show()